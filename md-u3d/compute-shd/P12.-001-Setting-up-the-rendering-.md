# 0 contents

P12.-001-Setting-up-the-rendering
P13.-002-A-simple-blur-effect
P14.-003-Night-vision-lenses
P15.-004-A-HUD-overlay---part-1
P16.-005-A-HUD-overlay---part-2
P17.-006-A-star-glow-effect-vertex
P18.-007-A-star-glow-effect-vertex
P19.-008-Challenge-Create-a-sepia-


# P12.-001-Setting-up-the-rendering
[00:00:00.000]   POST-PROCESSING.  Setting up the Render Pipeline
[00:00:17.000]   In this section we are going to look at using Compute Shaders to handle post-processing image effects.
在本节中，我们将介绍如何使用计算着色器来处理后处理图像效果。


[00:00:23.000]   To make this possible we will need to pass the rendered image to the shader and retrieve the image the shader creates.    A post-processing Compute Shader therefore will need at least two textures, one read-only and the other read-write. 
为了实现这一点，我们需要将渲染图像传递给着色器，并检索着色器创建的图像。   因此，后处理计算着色器将需要至少两个纹理，一个是只读的，另一个是读写的。


[00:00:40.000]   Because we are going to create several examples in this section, I have created a base class.

Open "BasePP.cs" in Visual Studio. The version in the start project is incomplete.
在Visual Studio中打开“BasePP.cs”。启动项目中的版本不完整。

Let's review the code that is in place.

[00:00:57.000 --> 00:01:06.000]   So we can use the effect in edit mode. We are going to use onEnable to initialise the data and onDisable to clear the data.
[00:01:06.000 --> 00:01:16.000]   Notice the properties that this base class has. First a public property, the actual Compute Shader, then the name of the kernel to call.
[00:01:16.000 --> 00:01:29.000]   We store the texture width and height in the Vector2Int property TextSize and the x and y values of the group size when calling Dispatch in the property GroupSize.
[00:01:29.000 --> 00:01:37.000]   The renderTextureRenderedSource will store the rendered image and the output texture is what the Compute Shader creates.
[00:01:37.000 --> 00:01:46.000]   Finally we store the integer value of the kernel we call and use a boolean value to indicate whether the data is initialised.
[00:01:46.000 --> 00:01:55.000]   The onEnable method calls the init function. Here we check if the system supports Compute Shaders and post an error message if it doesn't.
[00:01:55.000 --> 00:02:04.000]   We then check if the shader property is set, get the kernel handle and get the current camera and call the createTextures method.
[00:02:04.000 --> 00:02:11.000]   If all goes well then we set init to true. At the moment the createTextures method is empty.
[00:02:11.000 --> 00:02:35.000]   Let's fix that. Enter TextSize.x = ThisCamera.PixelWidth. TextSize.y = ThisCamera.PixelHeight. If Shader, uint x, y, Shader.GetKernelThreadGroupSizes, kernel handle, out x, out y, out, underscore.
[00:02:35.000 --> 00:02:53.000]   GroupSize.x = Mathf sealToInt floatTextSize.x/float x. GroupSize.y = Mathf sealToInt floatTextSize.y/float y.
[00:02:53.000 --> 00:03:10.000]   CreateTexture, ref, output. CreateTexture, ref, renderedSource. Shader.setTexture, kernel handle, source, renderedSource. Shader.setTexture, kernel handle, output, output.
[00:03:10.000 --> 00:03:16.000]   First we get the current pixel size of the camera and store it in the class property TextSize.
[00:03:16.000 --> 00:03:22.000]   The method createTexture will use this to determine the size of the createdTexture.
[00:03:22.000 --> 00:03:32.000]   If a shade has been defined then we get the size of the numThreads x and y value using the computeShader method getKernelThreadGroupSizes.
[00:03:32.000 --> 00:03:39.000]   Since we want the method to store the data in the past arguments we use the out parameter modifier.
[00:03:39.000 --> 00:03:47.000]   Usually changing the value of a parameter in a class would have no effect on the parameter once the program returns from the function
[00:03:47.000 --> 00:03:55.000]   because by default the parameter is passed by value and the function version of the variable is limited to the scope of the function.
[00:03:55.000 --> 00:04:04.000]   By using out we are passing by reference. Any change made in the function affects the variable at the scope of the caller.
[00:04:04.000 --> 00:04:07.000]   I really like this visual explanation of the difference.
[00:04:07.000 --> 00:04:14.000]   Filling the cup in the method fills the cup at the scope of the caller to the method if passed by reference.
[00:04:14.000 --> 00:04:21.000]   But when passed by value the source cup remains empty as it is filled in the method.
[00:04:21.000 --> 00:04:31.000]   Once we have the values for the x and y thread group sizes we can divide the TextSize by these values to get the group size for the x and y dimensions.
[00:04:31.000 --> 00:04:35.000]   Then we use the createTexture method to create a renderTexture.
[00:04:35.000 --> 00:04:41.000]   Here we create the render source and output textures and use the computeShader method setTexture
[00:04:41.000 --> 00:04:48.000]   to ensure the kernel with the ID kernel handle has the source and output textures set appropriately.
[00:04:48.000 --> 00:04:51.000]   We'll see these when we look at an actual shader later.
[00:04:51.000 --> 00:04:59.000]   Now when this script component is enabled we initialize the shader, create textures and pass these textures to the shader.
[00:04:59.000 --> 00:05:07.000]   You may have noticed that the dispatchWithSource method is empty and the checkResolution method only sets the resChanged value.
[00:05:07.000 --> 00:05:12.000]   Before we move on to a specific example we need to add code to these methods.


[00:05:12.000]   If you are familiar with Unity then you may know that there is a standard callback for a MonoBehaviour script onRenderImage.
This function has two parameters, a sourceTexture and a destinationTexture.
The sourceTexture is the image that Unity has rendered.
If you include such a method in your script then you must set the destinationImage,otherwise the output from the game will simply be a black screen.   The simplest option is to copy the source to the destination.
Here we set a virtual method, that's one we can override in a class that extends this class.


[00:05:50.000]   Where if in it is false or there is no shader then we simply copy the source to the destination using the Blit method of the graphics interface.
This will copy the source to the destination, scaling the textures if necessary.
In a later video in this section we'll see how this is achieved.

[00:06:09.000 --> 00:06:18.000]   If the shader is available and initialized then we call checkResolution and dispatch the shader using the source and destination textures.
[00:06:18.000 --> 00:06:26.000]   So far our basePostProcessing class has empty methods for checkResolution and dispatchWithSource.
[00:06:26.000 --> 00:06:28.000]   Let's fix that.
[00:06:28.000 --> 00:06:39.000]   In the checkResolution method add, if textSize.x is not equal to thisCamera.pixelWidth or textSize.y is not equal to thisCamera.pixelHeight,
[00:06:39.000 --> 00:06:43.000]   resChange = true, createTextures.
[00:06:43.000 --> 00:06:49.000]   We simply check if the camera's pixel dimensions matches the values set as textSize.
[00:06:49.000 --> 00:06:54.000]   If not then we set resChange to true and regenerate the textures.
[00:06:54.000 --> 00:06:57.000]   Now we move on to dispatchWithSource.
[00:06:57.000 --> 00:07:14.000]   Enter, graphics.blit, source, renderedSource, shader.dispatch, kernelHandle, groupSize.x, groupSize.y, 1. Graphics.blit, output, destination.
[00:07:14.000 --> 00:07:20.000]   The first step is to copy the source image to the compute shader's texture, renderSource.
[00:07:20.000 --> 00:07:29.000]   Then we dispatch the shader using the groupSizes we've calculated and finally we copy the shader's output to the destination.
[00:07:29.000 --> 00:07:36.000]   Before we complete this video let's create a really simple post-processing example using this base class.
[00:07:36.000 --> 00:07:48.000]   Open the scene RingHighlight and in Visual Studio open RingHighlight.cs from the scripts folder and RingHighlight.compute from the shaders folder.
[00:07:48.000]   If we look at the C# script notice it has the attribute ExecuteInEditMode.
This means each time anything in the scene changes there will be an update call which in turn will generate a call to the method onRenderImage.

[00:08:04.000 --> 00:08:11.000]   Notice we use the callback on Validate to pass the C# public properties to the shader.
[00:08:11.000 --> 00:08:21.000]   If we look now at the shader for each pixel in the source texture it copies it to the output texture so in fact at the moment it's doing nothing.
[00:08:21.000 --> 00:08:25.000]   Let's start to use the shader properties in the output color.
[00:08:25.000 --> 00:08:33.000]   Change the color assignment to FloatForSourceColor = SourceId.xy
[00:08:33.000 --> 00:08:37.000]   FloatForColor = SourceColor * Shade
[00:08:37.000 --> 00:08:42.000]   Now adjusting the shade property will darken the rendered image.
[00:08:42.000 --> 00:08:45.000]   The aim of this example is to highlight the avatar.
[00:08:45.000 --> 00:08:49.000]   We need the screen position of the avatar's hip bone.
[00:08:49.000 --> 00:08:53.000]   Notice the TractObject property is set to the hips transform.
[00:08:53.000 --> 00:08:57.000]   Add this code to the onRenderImage method.
[00:08:57.000 --> 00:09:17.000]   If TractObject and this camera, Vector3Pos = this camera, WorldToScreenPoint, TractObject.position, Center.x = Pos.x, Center.y = Pos.y, Shader.setVector, Center, Center.
[00:09:17.000 --> 00:09:20.000]   And add a new class property, Center.
[00:09:20.000 --> 00:09:29.000]   The camera method WorldToScreenPoint converts a world position into a screen coordinate, which is exactly what we need.
[00:09:29.000 --> 00:09:33.000]   We pass this value to the shader as the vector Center.
[00:09:33.000 --> 00:09:37.000]   The radius property is actually a proportional value.
[00:09:37.000 --> 00:09:40.000]   It's set to be a percentage of the render texture height.
[00:09:40.000 --> 00:09:45.000]   So if the resolution changes we should really update this property.
[00:09:45.000 --> 00:09:54.000]   Change the check resolution line to boolResChange = false, check resolution, out, ResChange.
[00:09:54.000 --> 00:09:57.000]   If ResChange set properties.
[00:09:57.000 --> 00:10:05.000]   All we need to do now is update the shader kernel to take the center, radius and edge width properties into consideration.
[00:10:05.000 --> 00:10:19.000]   Change color to ShadedSourceColor and add FloatHighlight = InCertile, Float2, ID.xy, Center.xy, Radius, EdgeWidth.
[00:10:19.000 --> 00:10:28.000]   FloatForColor = Lerp, ShadedSourceColor, SourceColor, Highlight.
[00:10:28.000] We use the included InCertile function. This takes the current pixel position Pt, a center value in screen coordinates, a radius property and an edge width and returns a value between 0 and 1.
If the point Pt is inside the circle defined by the center and radius, the return value will be 1.
Outside it will be 0.
Near the edge of the circle it will be an interpolated value between 0 and 1 because we're using the SmoothStep function.
[00:11:00.000 --> 00:11:03.000]   Now we can highlight the avatar.
[00:11:03.000 --> 00:11:11.000]   If we adjust the radius and soften edge values, we can resize the highlight circle and how soft its edge is.
[00:11:11.000 --> 00:11:23.000]   If we play the program and click around, the avatar will walk to the clicked location using a NavMesh agent, but the highlighting stays centered on the avatar.
[00:11:23.000 --> 00:11:25.000]   You've learnt a lot in this video.
[00:11:25.000 --> 00:11:32.000]   One, how to set up a source and destination texture. Two, how to pass these textures to the shader.
[00:11:32.000 --> 00:11:36.000]   And three, how to use on-render image with a compute shader.
[00:11:36.000 --> 00:11:40.000]   And in the next video we'll add a blur effect to this example.
[00:11:40.000 --> 00:11:42.000]   Keep watching!

# P13.-002-A-simple-blur-effect


[00:00:00.000 --> 00:00:17.960]   A simple Blair Effect When creating a Blair Effect, each pixel should
[00:00:17.960 --> 00:00:23.800]   be set as a blend of the pixels based on a radius value from the target.
[00:00:23.800 --> 00:00:31.200]   Suppose the target pixel is at position 100/220 in the rendered source texture, and the blur
[00:00:31.200 --> 00:00:40.520]   radius is 10, then we need to blend the pixels from 90/210 through to 110/230 to get the
[00:00:40.520 --> 00:00:43.680]   final colour for the target pixel.
[00:00:43.680 --> 00:00:51.160]   A single pixel needs to merge 20x20 source pixels, that's 400 pixels to consider for
[00:00:51.160 --> 00:00:53.000]   each pixel.
[00:00:53.000 --> 00:00:59.280]   To avoid such a high number of pixels to process, instead we turn this into two stages.
[00:00:59.280 --> 00:01:06.380]   First, we blur the image horizontally, and then use this to blur the image vertically.
[00:01:06.380 --> 00:01:08.400]   This is much more efficient.
[00:01:08.400 --> 00:01:15.460]   For each pixel horizontally, if blur radius is 10, we merge 20 pixels, and we do the same
[00:01:15.460 --> 00:01:23.040]   vertically, so instead of 400 pixels to consider for each target pixel, we have just 40, 20
[00:01:23.040 --> 00:01:26.520]   horizontally and 20 vertically.
[00:01:26.520 --> 00:01:32.880]   To allow us to handle this as a two stage process, we need a second kernel, and an additional
[00:01:32.880 --> 00:01:34.000]   texture.
[00:01:34.000 --> 00:01:39.520]   Open the scene blur highlight from the start project scenes folder, and in visual studio
[00:01:39.520 --> 00:01:46.200]   open blur highlight.cs from the scripts folder, and blur highlight.compute from the shaders
[00:01:46.200 --> 00:01:47.480]   folder.
[00:01:47.480 --> 00:01:53.400]   If you look at the C# script, you may notice it extends the BaseCompletePP class.
[00:01:53.400 --> 00:01:59.580]   BaseCompletePP is simply the completed version of the BasePP that you worked on in the previous
[00:01:59.580 --> 00:02:06.360]   video, just in case you didn't enter the code described in the previous video.
[00:02:06.360 --> 00:02:16.200]   Let's add a couple of class properties, enter render_texture_hors_output=null int kernel_hors_pass_id.
[00:02:16.200 --> 00:02:22.760]   Hors_output will store the result of the horizontal blur, and kernel_hors_pass_id will store the
[00:02:22.760 --> 00:02:26.220]   kernel_id for this horizontal pass.
[00:02:26.220 --> 00:02:36.140]   In the init method add kernel_hors_pass_id=shader.find_kernel_hors_pass, and in the create_textures method
[00:02:36.140 --> 00:02:43.980]   add shader.set_texture=kernel_hors_pass_id source, rendered source.
[00:02:43.980 --> 00:02:59.280]   Create texture ref_hors_output, shader.set_texture=kernel_hors_pass_id_hors_output_hors_output, shader.set_texture=kernel_handle_hors_output_hors_output.
[00:02:59.280 --> 00:03:04.540]   Now we have a kernel to call, and a texture to store the result.
[00:03:04.540 --> 00:03:10.660]   Notice that the second pass the highlight kernel also has a reference to hors_output, because
[00:03:10.660 --> 00:03:14.620]   with this second pass it's the source texture.
[00:03:14.620 --> 00:03:19.420]   If we look at the shader you can see that the source and the hors_output textures are
[00:03:19.420 --> 00:03:24.700]   both set as shared, because both kernels need access to them.
[00:03:24.700 --> 00:03:30.380]   Before we start to write the kernels for the shader, jump back to the C# script.
[00:03:30.380 --> 00:03:37.260]   Then you pass the public value blur radius to the shader.
[00:03:37.260 --> 00:03:44.980]   Blur radius is an integer value, so you add shader.set_int blur_radius blur_radius.
[00:03:44.980 --> 00:03:49.580]   Now we can focus on the code necessary to do the actual blurring.
[00:03:49.580 --> 00:04:02.060]   In the hors_pass_kernel add, int left = max(0) int id.x - blur_radius, int count = min blur_radius
[00:04:02.060 --> 00:04:17.340]   int id.x + min blur_radius source_length_x - int id.x, float for color = 0, uint2 index
[00:04:17.340 --> 00:04:24.980]   = uint2 uintleft id.y Unroll 100.
[00:04:24.980 --> 00:04:34.500]   For int x = 0, x < count, x++ Color + = source, index
[00:04:34.500 --> 00:04:44.840]   index.x++ Color Divide = float_count, hors_output id.xy = color
[00:04:44.840 --> 00:04:46.660]   This is super simple.
[00:04:46.660 --> 00:04:51.020]   We get the first pixel to start accumulating the color value.
[00:04:51.020 --> 00:04:54.660]   To avoid this being negative, we use the max function.
[00:04:54.660 --> 00:04:57.620]   Then we get the count of the pixels to scan.
[00:04:57.620 --> 00:05:04.700]   For most target pixels, this will be blur_radius times 2, but to the left and right extremes,
[00:05:04.700 --> 00:05:07.000]   we need to adjust this value.
[00:05:07.000 --> 00:05:13.300]   If blur_radius is 20, and the target pixel has an x value of 10, then we can only scan
[00:05:13.300 --> 00:05:18.980]   10 pixels to the left of the target, so count should be 30.
[00:05:18.980 --> 00:05:22.380]   Here's a table that should help you understand the values.
[00:05:22.380 --> 00:05:30.220]   I've set the width of the texture, source_length.x as 800 pixels, and blur_radius as 20.
[00:05:30.220 --> 00:05:37.220]   When x is 10, this is less than blur_radius, so in column 2 we get 10.
[00:05:37.220 --> 00:05:42.540]   Column 3, the minimum of 20 and 790, is clearly 20.
[00:05:42.540 --> 00:05:45.320]   Add them together, we get 30.
[00:05:45.320 --> 00:05:53.420]   Similar logic when x is near to the right side gives a count of 25 for x = 795.
[00:05:53.420 --> 00:06:01.900]   But between x = 20 and x = 780, the sum will always be blur_radius times 2 = 40.
[00:06:01.900 --> 00:06:08.540]   After combining count source pixels, we divide the sum by count to get the average, and set
[00:06:08.540 --> 00:06:11.200]   the hors_output to this value.
[00:06:11.200 --> 00:06:16.760]   If we switch source for hors_output in the highlight kernel, and then back in the C#
[00:06:16.760 --> 00:06:25.060]   script in the dispatchWithSource method, add shader.dispatch kernel_hors_pass_id groupsize.x
[00:06:25.060 --> 00:06:27.960]   groupsize.y 1.
[00:06:27.960 --> 00:06:32.100]   We get the result of the horizontal blur in pass.
[00:06:32.100 --> 00:06:36.460]   Can you write the code to do the vertical blur in the highlight kernel?
[00:06:36.460 --> 00:06:39.800]   It's very similar to the horizontal pass.
[00:06:39.800 --> 00:06:40.800]   Give it a try.
[00:06:40.800 --> 00:06:45.560]   Pause the video now.
[00:06:45.560 --> 00:06:47.420]   How did that go?
[00:06:47.420 --> 00:07:01.940]   My answer is int_top = max 0 int id.y - blur_radius int_count = min blur_radius int id.y + min
[00:07:01.940 --> 00:07:07.420]   blur_radius source_length_y - int id.y
[00:07:07.420 --> 00:07:17.220]   float_for_blur_color = 0 uint2_index = uint2 id.x uint_top
[00:07:17.220 --> 00:07:19.340]   Unroll 100.
[00:07:19.340 --> 00:07:28.300]   For int y = 0, y < count, y++ (check for typos, whoops, that shouldn't be there)
[00:07:28.300 --> 00:07:38.820]   Blur_color_plus = hors_output_index, index.y++ Blur_color_divide = float_count, output_id.xy
[00:07:38.820 --> 00:07:45.260]   = Blur_color Disabling and enabling the shader will regenerate
[00:07:45.260 --> 00:07:46.740]   the textures.
[00:07:46.740 --> 00:07:52.220]   If you're wondering about the unroll line, it makes the compiler expand the for loop.
[00:07:52.220 --> 00:07:57.460]   Instead of looping, the compiler will simply create a maximum of 100 copies of the code
[00:07:57.460 --> 00:08:03.860]   inside the for statement, updating the index variable x before moving to the next copy.
[00:08:03.860 --> 00:08:06.300]   It has a small performance boost.
[00:08:06.300 --> 00:08:11.780]   Now we have a completely blurred screen, but the aim is to have a circle around the avatar
[00:08:11.780 --> 00:08:13.700]   that's not blurred.
[00:08:13.700 --> 00:08:19.180]   It just remains to add this highlight ring, as we did in the previous video.
[00:08:19.180 --> 00:08:28.180]   Add float_for_source_color = source_id.xy float_for_shaded_blur_color = blur_color
[00:08:28.180 --> 00:08:35.660]   times shade float_highlight = incertl float_to id.xy
[00:08:35.660 --> 00:08:42.380]   center.xy radius edge width float_for_color = lerp
[00:08:42.380 --> 00:08:49.940]   shaded_blur_color = source_color highlight And change the output line to use color.
[00:08:49.940 --> 00:08:53.980]   Now we have an area where the source pixels show through.
[00:08:53.980 --> 00:08:56.020]   Great!
[00:08:56.020 --> 00:08:59.100]   This style of blur is the simplest.
[00:08:59.100 --> 00:09:04.860]   Another option for blurring is Gaussian Blurs, named after the famous German mathematician
[00:09:04.860 --> 00:09:07.300]   Carl Friedrich Gauss.
[00:09:07.300 --> 00:09:10.300]   Here we use a weighted value for each pixel.
[00:09:10.300 --> 00:09:14.420]   The further away from the target pixel, the lower the weight.
[00:09:14.420 --> 00:09:20.520]   If you open the scene Gaussian Blur Highlight, and the accompanying C# script, and Compute
[00:09:20.520 --> 00:09:25.460]   Shader, you'll see that we use a buffer to store the weights.
[00:09:25.460 --> 00:09:30.660]   We only need a one-dimensional array of values, which are calculated in the set_weights array
[00:09:30.660 --> 00:09:31.660]   method.
[00:09:31.660 --> 00:09:34.460]   It uses this function.
[00:09:34.460 --> 00:09:38.420]   The fraction with the square root becomes the constant c.
[00:09:38.420 --> 00:09:42.380]   This function gives a classic normal distribution curve.
[00:09:42.380 --> 00:09:47.540]   By using this weighted distribution in the shader, we give more dominance to the pixels
[00:09:47.540 --> 00:09:50.020]   nearest to the target pixel.
[00:09:50.020 --> 00:09:54.340]   The result, a more attractive blurring filter.
[00:09:54.340 --> 00:10:00.500]   In the next video we look at creating an image filter to give this night vision lens effect.
[00:10:00.500 --> 00:10:01.220]   See you there!

# P14.-003-Night-vision-lenses

[00:00:00.000 --> 00:00:12.800]   [Music]
[00:00:12.800 --> 00:00:15.000]   Night Vision Lenses
[00:00:15.000 --> 00:00:19.000]   In this video we're going to combine techniques you've learned so far
[00:00:19.000 --> 00:00:23.000]   to create a night vision lenses effect like this
[00:00:23.000 --> 00:00:27.000]   The first step is to make the image lower resolution
[00:00:27.000 --> 00:00:32.000]   This is easily achieved simply by dividing the id.xy vector
[00:00:32.000 --> 00:00:36.000]   by a value and then multiplying it by the same value
[00:00:36.000 --> 00:00:41.000]   Because the division is using integer values we get a repeated result
[00:00:41.000 --> 00:00:47.000]   If the division is 3 then here are the results for the bottom left corner
[00:00:47.000 --> 00:00:55.000]   If id.xy is 0,0 then dividing by 3 and multiplying by 3 has no effect
[00:00:55.000 --> 00:01:02.000]   But if id.xy is at 2,2 then integer division by 3 gives the result 0,0
[00:01:02.000 --> 00:01:07.000]   So multiplying by 3 keeps this as 0,0
[00:01:07.000 --> 00:01:16.000]   If id.xy is 4,6 then division by 3 gives 1,2 and multiplying by 3 gives 3,6
[00:01:16.000 --> 00:01:19.000]   Open the scene Night Vision in Unity
[00:01:19.000 --> 00:01:27.000]   And you guessed it, nightvision.cs from the scripts folder and nightvision.compute from the shaders folder
[00:01:27.000 --> 00:01:32.000]   In the compute shader find the cs main kernel and add this code
[00:01:32.000 --> 00:01:57.000]   The result a much more low resolution image, but the image is too sharp
[00:01:57.000 --> 00:02:00.000]   Let's introduce some noise into the mix
[00:02:00.000 --> 00:02:07.000]   float noise = random float2 id.xy time
[00:02:07.000 --> 00:02:10.000]   and change the source color assignment line to
[00:02:10.000 --> 00:02:18.000]   float3 source color = lerp source id.xy.rgb * 2
[00:02:18.000 --> 00:02:22.000]   source index.rgb noise
[00:02:22.000 --> 00:02:29.000]   Now if we play the video we get a result that's closer to a low resolution camera image
[00:02:29.000 --> 00:02:34.000]   Usually a night vision camera is monochrome, often tinted green
[00:02:34.000 --> 00:02:36.000]   Let's add a tint
[00:02:36.000 --> 00:02:45.000]   float3 greyscale = sourcecolor.r + sourcecolor.g + sourcecolor.b / 3
[00:02:45.000 --> 00:02:51.000]   float3 tinted = greyscale * tintcolor.rgb
[00:02:51.000 --> 00:02:57.000]   float3 finalcolor = lerp sourcecolor tinted tint strength
[00:02:57.000 --> 00:03:01.000]   And delete the previous final color assignment line
[00:03:01.000 --> 00:03:03.000]   That's more like it
[00:03:03.000 --> 00:03:08.000]   First we create a greyscale image by adding together the red, green and blue channels
[00:03:08.000 --> 00:03:11.000]   and dividing the result by 3
[00:03:11.000 --> 00:03:16.000]   Then we create a tinted image using the tint color pass from the C# script
[00:03:16.000 --> 00:03:22.000]   And finally we merge the result using the lerp function and the tint strength property
[00:03:22.000 --> 00:03:24.000]   It's looking better
[00:03:24.000 --> 00:03:28.000]   Often there's a rolling scanline on an old style monitor
[00:03:28.000 --> 00:03:30.000]   Let's add this in
[00:03:30.000 --> 00:03:37.000]   float uvy = float id.y / float source.length.y
[00:03:37.000 --> 00:03:44.000]   float scanline = saturate smoothstep 0.1 0.2
[00:03:44.000 --> 00:04:02.000]   uvy * lines + time * 3 + 0.3 finalcolor = lerp source id.xy.rgb * 0.5 finalcolor scanline
[00:04:02.000 --> 00:04:05.000]   Now we have a rolling scanline
[00:04:05.000 --> 00:04:09.000]   We're really making the render look messy, nice
[00:04:09.000 --> 00:04:13.000]   Here we convert the y value to a value in the range 0 to 1
[00:04:13.000 --> 00:04:22.000]   Then we determine if we're in a scanline by taking the fractional part of uvy * lines + times * 3
[00:04:22.000 --> 00:04:26.000]   Lines is the number of scanlines in the vertical height
[00:04:26.000 --> 00:04:30.000]   By multiplying the uvy value by this number
[00:04:30.000 --> 00:04:32.000]   Then taking the fractional part
[00:04:32.000 --> 00:04:38.000]   We effectively divide the screen into lines count 0 to 1 ranges
[00:04:38.000 --> 00:04:46.000]   To focus the result we make anything less than 0.1 = 0 and anything above 0.2 = 1
[00:04:46.000 --> 00:04:50.000]   This range controls the height of an individual scanline
[00:04:50.000 --> 00:04:55.000]   To avoid them being too strong we add 0.3 to the value
[00:04:55.000 --> 00:05:01.000]   So even when the return value from smoothstep is 0, scanline is 0.3
[00:05:01.000 --> 00:05:07.000]   The last line in this section uses the scanline value, in reverse effectively
[00:05:07.000 --> 00:05:12.000]   Where scanline is the lowest value the darkened source image shows through
[00:05:12.000 --> 00:05:14.000]   Based on the lerp function
[00:05:14.000 --> 00:05:18.000]   If scanline is 1 then just the finalcolor value is set
[00:05:18.000 --> 00:05:24.000]   Remember for lerp a, b, n the return value is this
[00:05:24.000 --> 00:05:28.000]   If scanline = n = 1 we get this
[00:05:28.000 --> 00:05:34.000]   So finalcolor = b is set as the existing value of finalcolor
[00:05:34.000 --> 00:05:38.000]   Where scanline = n = 0 we get this
[00:05:38.000 --> 00:05:42.000]   So finalcolor is set to the darkened source image
[00:05:42.000 --> 00:05:45.000]   Now we need to add the binoculars effect
[00:05:45.000 --> 00:05:48.000]   Can you try and add a monocular effect?
[00:05:48.000 --> 00:05:53.000]   This is just the same as the highlight effect we've used in the previous two videos
[00:05:53.000 --> 00:05:57.000]   Pause the video now and give it a try
[00:05:57.000 --> 00:05:59.000]   How did that one go?
[00:05:59.000 --> 00:06:06.000]   Even if you find it difficult it's still worth doing because practice is how you'll really get the hang of it
[00:06:06.000 --> 00:06:11.000]   My answer is float2pt = float2id.xy
[00:06:11.000 --> 00:06:17.000]   float2center = float2source.length * 0.5
[00:06:17.000 --> 00:06:24.000]   floatinvision = inCertl, ptCenter, radius, edgeWidth
[00:06:24.000 --> 00:06:26.000]   float3black = 0
[00:06:26.000 --> 00:06:31.000]   finalcolor = lerp, black, finalcolor, inVision
[00:06:31.000 --> 00:06:34.000]   Now we have a monocular effect
[00:06:34.000 --> 00:06:40.000]   We get the point to test pt by simply casting id.xy to a float2 value
[00:06:40.000 --> 00:06:44.000]   Center is just the source length property divided by 2
[00:06:44.000 --> 00:06:47.000]   Here we multiply it by 0.5
[00:06:47.000 --> 00:06:51.000]   We now have the values to use in the inCertl function
[00:06:51.000 --> 00:06:58.000]   Once we have the inVision value we can lerp the final color we have with black based on this return value
[00:06:58.000 --> 00:07:05.000]   To give a binocular effect we need to calculate the value for the left and right lenses
[00:07:05.000 --> 00:07:08.000]   Adjusting the center value for each
[00:07:08.000 --> 00:07:11.000]   Then merge the two values to get the inVision value
[00:07:11.000 --> 00:07:24.000]   Center.x -= radius * 0.7, floatLeftLens = inCertl, ptCenter, radius, edgeWidth
[00:07:24.000 --> 00:07:33.000]   Center.x += radius * 1.4, floatRightLens = inCertl, ptCenter, radius, edgeWidth
[00:07:33.000 --> 00:07:38.000]   floatinvision = saturate, leftLens + rightLens
[00:07:38.000 --> 00:07:44.000]   Remember saturate ensures that the value is kept between the range 0 and 1
[00:07:44.000 --> 00:07:48.000]   And hey presto we have a night vision lens effect
[00:07:48.000 --> 00:07:52.000]   Don't forget to disable enable the script each time you update the shader
[00:07:52.000 --> 00:07:55.000]   To ensure the shader is initialized correctly
[00:07:55.000 --> 00:07:58.000]   The shader looks best when the game's playing
[00:07:58.000 --> 00:08:03.000]   Then the noise gives the best effect and the rolling scanline scene
[00:08:03.000 --> 00:08:07.000]   In the next video we'll look at creating a HUD overlay
[00:08:07.000 --> 00:08:09.000]   Catch you there!




# P15.-004-A-HUD-overlay---part-1

[00:00:00.000 --> 00:00:15.680]   A HUD Overlay - Part 1
[00:00:15.680 --> 00:00:21.820]   In this video and the next, we're going to create a HUD Overlay, like this.
[00:00:21.820 --> 00:00:27.260]   We'll do this by drawing lines, circles, polygons and rotating fills.
[00:00:27.260 --> 00:00:35.000]   From the scene HUD_OVERLAY in Unity and HUD_OVERLAY.CS and HUD_OVERLAY.COMPUTE in Visual Studio.
[00:00:35.000 --> 00:00:39.800]   There's just a single white line over the rendered output at the moment.
[00:00:39.800 --> 00:00:44.680]   Before we add more to the shader, let's review the existing code.
[00:00:44.680 --> 00:00:47.380]   The shader has some useful functions.
[00:00:47.380 --> 00:00:54.760]   The function online checks if parameter 1, x, is within line width of parameter 2, y.
[00:00:54.760 --> 00:00:57.960]   If they are, then the return value is 1.
[00:00:57.960 --> 00:01:00.760]   We use SmoothStep twice.
[00:01:00.760 --> 00:01:06.320]   This is a common technique for checking if a value is between limits.
[00:01:06.320 --> 00:01:10.880]   Suppose we're testing to see if a point is on a line with line width 2 and edge width
[00:01:10.880 --> 00:01:13.440]   0.1.
[00:01:13.440 --> 00:01:16.680]   Suppose x=10 and y=9.
[00:01:16.680 --> 00:01:22.400]   Here the return value should be 1, because y is within line width of 10.
[00:01:22.400 --> 00:01:36.800]   The code line becomes SmoothStep 10-2/2-0.1 10-2/2=9, which simplifies to SmoothStep 8.999,
[00:01:36.800 --> 00:01:38.440]   which equals 1.
[00:01:38.440 --> 00:01:44.040]   The third parameter is greater or equal to the second, so the return value is 1.
[00:01:44.040 --> 00:01:47.640]   We're effectively testing if the point is in this region.
[00:01:47.640 --> 00:01:57.800]   The second part of the line becomes 10+2/2 10+2/2+0.19, which simplifies to SmoothStep
[00:01:57.800 --> 00:02:03.120]   11 11.19, which equals 0.
[00:02:03.120 --> 00:02:09.120]   The third parameter is less than the first, so the return value is 0.
[00:02:09.120 --> 00:02:14.240]   Here we tested if the point is in this region, but because we subtract this value we're actually
[00:02:14.240 --> 00:02:21.240]   testing if the point is in this region, because we want the case where it's not in this region.
[00:02:21.240 --> 00:02:26.160]   The two SmoothStep results give 1-0, which equals 1.
[00:02:26.160 --> 00:02:33.680]   OnLine returns 1, for x=10, y=9, if line width is set to 2.
[00:02:33.680 --> 00:02:37.080]   How about x=10 and y=15?
[00:02:37.080 --> 00:02:52.920]   Now we get SmoothStep 10-2/2-0.1 10-2/2=15, minus SmoothStep 10+2/2 10+2/2+0.1=15, which
[00:02:52.920 --> 00:03:01.880]   simplifies to SmoothStep 8.999-15, minus SmoothStep 11 11.1=15.
[00:03:01.880 --> 00:03:07.360]   The return values are 1-1, which equals 0.
[00:03:07.360 --> 00:03:13.400]   Because for the first SmoothStep 15 is greater than 9, it is in this region, but for the
[00:03:13.400 --> 00:03:21.440]   second SmoothStep 15 is also greater than 11.1, so the point is also in this region.
[00:03:21.440 --> 00:03:25.720]   Again to stress, because we subtract this result, we're really testing if the point
[00:03:25.720 --> 00:03:33.440]   is in this region, we get 1-1 which is 0, with x=10 and y=15 the point's not on the
[00:03:33.440 --> 00:03:35.480]   line.
[00:03:35.480 --> 00:03:40.040]   Another common feature of overlay shaders is the need to convert between coordinate
[00:03:40.040 --> 00:03:41.640]   systems.
[00:03:41.640 --> 00:03:46.760]   All we know about the pixel we're dealing with is the screen position in pixels.
[00:03:46.760 --> 00:03:50.200]   ID.xy gives the pixel coordinate.
[00:03:50.200 --> 00:03:56.160]   Hopefully you know by now that using this coordinate system we have 0,0 at the bottom
[00:03:56.160 --> 00:04:00.680]   left and source length x,y at the top right.
[00:04:00.680 --> 00:04:05.880]   In this example we want to ensure that the lines we draw are all on screen.
[00:04:05.880 --> 00:04:11.640]   The screen shape may be anything from wider than it is tall to taller than it is wide.
[00:04:11.640 --> 00:04:16.360]   If it's taller than it is wide then the limiting factor will be the width.
[00:04:16.360 --> 00:04:22.040]   If it's wider than it is tall then the limiting factor for scaling will be the height.
[00:04:22.040 --> 00:04:30.800]   We set up a centre at 0.50.5, then we check the aspect ratio, width/height.
[00:04:30.800 --> 00:04:36.640]   If this is greater than 1, then is the source texture wider than it is tall, or taller than
[00:04:36.640 --> 00:04:38.240]   it is wide?
[00:04:38.240 --> 00:04:41.760]   Pause the video if you need to think about it.
[00:04:41.760 --> 00:04:44.960]   Yes, it's wider than it is tall.
[00:04:44.960 --> 00:04:51.560]   For the sake of simplicity imagine we have a source texture resolution of 1,500.
[00:04:51.560 --> 00:04:56.800]   The aspect ratio is 1,000/500 which equals 2.
[00:04:56.800 --> 00:05:03.680]   We're going to convert our coordinates so that the 500 becomes 1 by dividing ID.xy stored
[00:05:03.680 --> 00:05:10.800]   as the float2 value uv by source.length.y which equals 500.
[00:05:10.800 --> 00:05:17.720]   Now we're working with a coordinate system where 00 is bottom left and 21 is top right.
[00:05:17.720 --> 00:05:25.560]   1000 is divided by 500 for the x values and 500 by 500 for the y values.
[00:05:25.560 --> 00:05:31.840]   Now the vertical centre is still at 0.5, the value we use when creating the centre, but
[00:05:31.840 --> 00:05:34.840]   the horizontal centre is at 1.
[00:05:34.840 --> 00:05:40.280]   To convert centre.x to 1 we simply multiply by the aspect ratio of 2.
[00:05:40.280 --> 00:05:44.080]   Now centre is at 1, 0.5.
[00:05:44.080 --> 00:05:49.000]   A similar logic applies if the source texture is taller than it is wide.
[00:05:49.000 --> 00:05:51.840]   Suppose we have 400, 800.
[00:05:51.840 --> 00:05:54.760]   Now aspect ratio is 0.5.
[00:05:54.760 --> 00:06:01.780]   Dividing x and y by x we get 1,2, with the centre at 0.51.
[00:06:01.780 --> 00:06:10.600]   To convert 0.5, 0.5 to 0.51 we divide the y value by the aspect ratio, 0.5 divided by
[00:06:10.600 --> 00:06:14.480]   0.5 equals 1, as required.
[00:06:14.480 --> 00:06:19.220]   Now we have a coordinate system to use, uv, and a centre.
[00:06:19.220 --> 00:06:24.400]   To create a HUD overlay we need to merge our overlay with the rendered source.
[00:06:24.400 --> 00:06:29.940]   To do this we need to generate an alpha value by simply taking the sum of the red, green
[00:06:29.940 --> 00:06:34.080]   and blue components of the calculated colour value.
[00:06:34.080 --> 00:06:40.320]   The HLSL function saturate and shows the value is in the range 0 to 1.
[00:06:40.320 --> 00:06:45.300]   Then we use alert function again to merge the source pixel and our overlay using this
[00:06:45.300 --> 00:06:49.760]   calculated alpha value as the proportional value.
[00:06:49.760 --> 00:06:55.720]   Where alpha is 1 we see the overlay and where alpha is 0 we see the source.
[00:06:55.720 --> 00:06:57.560]   Let's add another line.
[00:06:57.560 --> 00:07:02.920]   Below the colour line can you add a y axis at the centre of the screen?
[00:07:02.920 --> 00:07:06.760]   Pause the video and give it a try.
[00:07:06.760 --> 00:07:08.880]   Not too hard that one.
[00:07:08.880 --> 00:07:21.600]   Colour plus equals, online, uv.x, centre.x, 0.002, 0.001, times xcolour.rgb.
[00:07:21.600 --> 00:07:28.400]   By summing the new value with the existing one and using the calculated uv.x and centre.x
[00:07:28.400 --> 00:07:32.920]   values we get a vertical line in the middle of the screen.
[00:07:32.920 --> 00:07:35.500]   Now let's add some circular lines.
[00:07:35.500 --> 00:07:48.360]   Colour plus equals, circle, uv, centre, 0.45, 0.002, 0.001, times axiscolour.rgb.
[00:07:48.360 --> 00:07:51.820]   Now we're combining two lines and a circle.
[00:07:51.820 --> 00:07:57.160]   We're using the uv coordinate space and our calculated centre.
[00:07:57.160 --> 00:07:59.520]   Let's add two more circles.
[00:07:59.520 --> 00:08:07.360]   Copy the existing circle line twice, setting the third parameter to 0.3 and 0.15.
[00:08:07.360 --> 00:08:11.120]   Pause the video and give it a try.
[00:08:11.120 --> 00:08:15.640]   Yes you just copied the circle line twice, changing the radius value.
[00:08:15.640 --> 00:08:17.760]   Now we've completed the static lines.
[00:08:17.760 --> 00:08:22.000]   We'll pause there and in the next video add some moving effects.
[00:08:22.000 --> 00:08:22.960]   Catch you in a minute.



# P16.-005-A-HUD-overlay---part-2

[00:00:00.000 --> 00:00:16.300]   A HUD Overlay - Part 2
[00:00:16.300 --> 00:00:21.200]   In the previous video we learnt how to add a simple overlay to the rendered output.
[00:00:21.200 --> 00:00:24.720]   In this video we are going to add some moving effects.
[00:00:24.720 --> 00:00:34.760]   Back in HUDOverlay.compute, add this code, color plus equals sweep, uv, center, 0.45,
[00:00:34.760 --> 00:00:42.120]   0.003, 0.001, times sweepColor.RGB.
[00:00:42.120 --> 00:00:46.080]   If you play the game you should now have a line that's rotating around the center of
[00:00:46.080 --> 00:00:47.080]   the screen.
[00:00:47.080 --> 00:00:50.000]   It uses the sweep method.
[00:00:50.000 --> 00:00:51.880]   Take a look at this method.
[00:00:51.880 --> 00:00:58.040]   First we create a point D that is the test point moved to the center of rotation.
[00:00:58.040 --> 00:01:00.000]   Then we create an angle theta.
[00:01:00.000 --> 00:01:03.040]   To get this angle we just take the current time.
[00:01:03.040 --> 00:01:06.800]   You may have noticed this is passed by the C# script.
[00:01:06.800 --> 00:01:13.160]   Then we create a vector from the origin to cos theta minus sine theta multiplied by radius.
[00:01:13.160 --> 00:01:18.960]   So now we have two vectors, both in relation to a center of 0,0.
[00:01:18.960 --> 00:01:22.220]   Then we use the HLSL function dot.
[00:01:22.220 --> 00:01:25.560]   This takes the dot product of two vectors.
[00:01:25.560 --> 00:01:30.880]   If we have two float two variables a and b, then the dot product is a float value that
[00:01:30.880 --> 00:01:34.980]   is the sum of the multiples of each component.
[00:01:34.980 --> 00:01:40.640]   So it is a dot x times b dot x plus a dot y times b dot y.
[00:01:40.640 --> 00:01:46.560]   Dividing the dot product of d dot p by the dot product of p dot p, we actually project
[00:01:46.560 --> 00:01:50.080]   our point onto the line we are considering.
[00:01:50.080 --> 00:01:54.040]   H becomes a proportional value of the p vector.
[00:01:54.040 --> 00:01:57.520]   In the diagram it would be about 0.3ish.
[00:01:57.520 --> 00:02:02.800]   To get to the point that is the intersection of the line through D and the vector p, you
[00:02:02.800 --> 00:02:06.480]   simply multiply p by h.
[00:02:06.480 --> 00:02:11.560]   Then we clamp this between 0 and 1, so we are only considering the point when over the
[00:02:11.560 --> 00:02:14.140]   line from center to p.
[00:02:14.140 --> 00:02:19.440]   If the test point is below the origin then the dot product will be negative, and above
[00:02:19.440 --> 00:02:22.440]   the end point of the line it will be above 1.
[00:02:22.440 --> 00:02:28.200]   By clamping between 0 and 1 we ensure we only return a positive value between the start
[00:02:28.200 --> 00:02:30.920]   and end points of our sweeping line.
[00:02:30.920 --> 00:02:37.400]   Try replacing the h assignment line with just dot dp divided by dot pp.
[00:02:37.400 --> 00:02:40.820]   As you see the line goes across the screen.
[00:02:40.820 --> 00:02:46.480]   Now we need to calculate how far our test point is from the sweeping line.
[00:02:46.480 --> 00:02:51.520]   This is given by the length of the vector d minus p times h.
[00:02:51.520 --> 00:02:56.920]   Remember that d is a line from the origin to our test point, and that p is a vector
[00:02:56.920 --> 00:03:00.560]   from the origin to the end of our sweeping line.
[00:03:00.560 --> 00:03:05.560]   The aim is to find the closest point on the line p to d.
[00:03:05.560 --> 00:03:10.600]   This will be on a line that goes through D and is perpendicular to p.
[00:03:10.600 --> 00:03:15.060]   p times h is the point on this line which is closest to D.
[00:03:15.060 --> 00:03:19.360]   D minus p times h gives this vector.
[00:03:19.360 --> 00:03:23.300]   Finding the length of this line gives the distance of our test point from the sweeping
[00:03:23.300 --> 00:03:24.540]   line.
[00:03:24.540 --> 00:03:30.260]   If this is under the value line width then we return 1 from this function.
[00:03:30.260 --> 00:03:35.360]   Take a look at the code pen 'Understanding using dot products' to calculate the distance
[00:03:35.360 --> 00:03:38.800]   to a line segment at this address.
[00:03:38.800 --> 00:03:43.900]   Use the change view button and the edit layout options to change the layout.
[00:03:43.900 --> 00:03:46.800]   Drag the test point around and see what's happening.
[00:03:46.800 --> 00:03:50.100]   The red dot shows the test point that you can drag around.
[00:03:50.100 --> 00:03:54.760]   The green line is the vector d and the black line the vector p.
[00:03:54.760 --> 00:04:01.460]   The blue line shows the perpendicular vector between the sweeping line p and the test point.
[00:04:01.460 --> 00:04:05.040]   The aim is to discover the length of this line.
[00:04:05.040 --> 00:04:10.340]   Usually we find a point along the sweep line and then we walk back along the line p and
[00:04:10.340 --> 00:04:12.140]   then up the line d.
[00:04:12.140 --> 00:04:16.700]   This gives a vector from where the test point is projected onto the line p.
[00:04:16.700 --> 00:04:23.420]   Dot products are very useful in determining how one vector is projected onto another.
[00:04:23.420 --> 00:04:25.500]   Let's create a trailing edge.
[00:04:25.500 --> 00:04:28.260]   Add this code to the sweep function.
[00:04:28.260 --> 00:04:35.100]   Float gradient equals 0, cons float gradient angle equals pi times 0.5.
[00:04:35.100 --> 00:04:43.660]   If length d is less than radius, float angle equals f mod theta plus a tan 2 d dot y d
[00:04:43.660 --> 00:04:46.500]   dot x pi 2.
[00:04:46.500 --> 00:04:53.780]   Gradient equals clamp gradient angle minus angle 0, gradient angle divided by gradient
[00:04:53.780 --> 00:04:59.340]   angle times 0.5 and add gradient to the return value.
[00:04:59.340 --> 00:05:03.260]   Now we have a trailing gradient behind the trailing line.
[00:05:03.260 --> 00:05:05.060]   How is this achieved?
[00:05:05.060 --> 00:05:10.740]   We want to return a value for gradient that is 0 if the angle between our test point and
[00:05:10.740 --> 00:05:15.360]   the sweeping line is at the value we've set for gradient angle.
[00:05:15.360 --> 00:05:18.340]   This is the maximum range for our gradient.
[00:05:18.340 --> 00:05:26.780]   If the angle is 0 then we return 0.5 and if the angle is half gradient angle we get 0.25.
[00:05:26.780 --> 00:05:32.300]   A tan 2 returns the angle in radians between the positive x axis and the line from the
[00:05:32.300 --> 00:05:34.640]   centre to d.
[00:05:34.640 --> 00:05:38.820]   The return value is in the range plus or minus pi.
[00:05:38.820 --> 00:05:42.580]   F mod gives the floating point remainder after division.
[00:05:42.580 --> 00:05:50.020]   For example f mod 13, 3 here 13 divided by 3 equals 4 and 1 remaining.
[00:05:50.020 --> 00:05:53.580]   So f mod 13, 3 equals 1.
[00:05:53.580 --> 00:05:58.820]   We use f mod to ensure angle can only be in the range of one revolution.
[00:05:58.820 --> 00:06:03.140]   Remember that 2 pi is a complete revolution in radians.
[00:06:03.140 --> 00:06:07.820]   Clamp simply keeps the value between 0 and gradient angle.
[00:06:07.820 --> 00:06:10.860]   Sorry to give so much math in this video.
[00:06:10.860 --> 00:06:17.540]   The important takeaway is that you can use the HLSL functions, a tan 2, f mod and clamp
[00:06:17.540 --> 00:06:19.860]   to create gradients.
[00:06:19.860 --> 00:06:25.780]   Before we finish let's add a couple of triangles using the polygon function we've met already.
[00:06:25.780 --> 00:06:29.980]   Just a reminder a guide to how the polygon function works is in the last section in this
[00:06:29.980 --> 00:06:31.660]   course.
[00:06:31.660 --> 00:06:40.800]   Parameter float offset equals sine times times 4 times 0.05 plus 0.5, colour plus equals
[00:06:40.800 --> 00:06:54.740]   polygon UV float to centre dot x plus offset, centre dot y, 0.008, 3, 0, 0.001 times white.
[00:06:54.740 --> 00:07:01.020]   Then copy the polygon line and change offset to minus and the fifth parameter to pi.
[00:07:01.020 --> 00:07:05.780]   This puts the triangle on the left pointing right, the first ones on the right pointing
[00:07:05.780 --> 00:07:07.040]   left.
[00:07:07.040 --> 00:07:12.020]   The centre value passed to the polygon function uses sine and time.
[00:07:12.020 --> 00:07:17.340]   As you know sine returns a value between minus 1 and 1 as the passed parameter increases
[00:07:17.340 --> 00:07:19.300]   by 2 pi.
[00:07:19.300 --> 00:07:25.160]   Here we use time times 4 as the parameter so we'll go through a full cycle in 2 pi divided
[00:07:25.160 --> 00:07:29.220]   by 4 seconds, about 1.6 seconds.
[00:07:29.220 --> 00:07:36.420]   We multiply the sine value by 0.05 so the range of values are plus and minus 0.05 and
[00:07:36.420 --> 00:07:44.620]   we add 0.5 to the value making offset in the range 0.45 to 0.55 and that is a whirlwind
[00:07:44.620 --> 00:07:48.740]   trip through using shaping functions to generate a HUD overlay.
[00:07:48.740 --> 00:07:54.340]   Later in the course we'll need some shaders that use Unity's shader lab syntax, that's
[00:07:54.340 --> 00:07:56.920]   the usual Unity shader.
[00:07:56.920 --> 00:08:01.900]   In preparation for that, the last example in this section involves creating a post-processing
[00:08:01.900 --> 00:08:05.400]   effect using a vertex fragment shader.
[00:08:05.400 --> 00:08:06.100]   See you there!



# P17.-006-A-star-glow-effect-vertex

[00:00:00.000 --> 00:00:18.760]   A Starglow Effect - Vertex Fragment Shaders - Part 1
[00:00:18.760 --> 00:00:23.400]   Although this course is about writing and understanding compute shaders, for some jobs
[00:00:23.400 --> 00:00:29.020]   you will need to know how to work with the standard Unity Vertex Fragment Shader.
[00:00:29.020 --> 00:00:35.960]   In this video I'll introduce you to the way Unity handles these via ShaderLab syntax.
[00:00:35.960 --> 00:00:42.160]   Open the scene Starglow and in Visual Studio open Starglow.cs from the scripts folder and
[00:00:42.160 --> 00:00:46.320]   Starglow.shader from the shaders folder.
[00:00:46.320 --> 00:00:49.020]   Let's have a look at the C# script.
[00:00:49.020 --> 00:00:53.240]   We have a number of public properties that can be adjusted in the inspector.
[00:00:53.240 --> 00:00:55.560]   We'll meet these later.
[00:00:55.560 --> 00:00:59.880]   Using the start method we collect the IDs of the shaders properties.
[00:00:59.880 --> 00:01:03.360]   This is more efficient than using strings to access them.
[00:01:03.360 --> 00:01:09.120]   We'll use these IDs later when we pass these values to the shader.
[00:01:09.120 --> 00:01:14.720]   The script uses onRenderImage which at the moment simply passes the source to the destination.
[00:01:14.720 --> 00:01:17.880]   OK, over to the shader.
[00:01:17.880 --> 00:01:23.320]   A shader has a name and by using forward slash you are telling Unity to place the shader
[00:01:23.320 --> 00:01:24.920]   in a folder.
[00:01:24.920 --> 00:01:30.560]   So when adding this shader to a material you'll find it in the image effect folder and the
[00:01:30.560 --> 00:01:33.600]   shader will be called Starglow.
[00:01:33.600 --> 00:01:36.440]   Using ShaderLab you have a properties section.
[00:01:36.440 --> 00:01:41.720]   Here we have just two properties, main text and brightness settings.
[00:01:41.720 --> 00:01:46.740]   As we develop this app we'll use the graphics blip method several times and this method
[00:01:46.740 --> 00:01:48.920]   will use our shader.
[00:01:48.920 --> 00:01:53.920]   Inside the shader the first parameter to the blip method, the source, will be set as the
[00:01:53.920 --> 00:01:56.040]   main text.
[00:01:56.040 --> 00:02:00.200]   Notice this is a sampler 2D type in the subshader chunk.
[00:02:00.200 --> 00:02:03.760]   Now look at the subshader and notice it has a pass chunk.
[00:02:03.760 --> 00:02:07.160]   A shader can contain several passes.
[00:02:07.160 --> 00:02:11.200]   This very simple pass is a vertex fragment shader.
[00:02:11.200 --> 00:02:13.720]   That means it has two stages.
[00:02:13.720 --> 00:02:18.600]   First it converts the vertices in a mesh to homogeneous clip space.
[00:02:18.600 --> 00:02:19.600]   Ouch!
[00:02:19.600 --> 00:02:21.240]   What's that?
[00:02:21.240 --> 00:02:29.160]   Simple really, each vertex is a float 4 vector and if we divide x, y, z by w we get normalised
[00:02:29.160 --> 00:02:31.160]   device coordinates.
[00:02:31.160 --> 00:02:36.480]   That is, the three dimensions are converted to the coordinate space minus 1 to 1.
[00:02:36.480 --> 00:02:43.520]   If a vertex is to appear on screen then it must have a value between minus 1 and 1.
[00:02:43.520 --> 00:02:48.440]   Minus 1 minus 1 is the bottom left and 1, 1 the top right.
[00:02:48.440 --> 00:02:54.240]   The pragma defines the vertex function, it's the name that follows vertex.
[00:02:54.240 --> 00:02:57.080]   So where's the function vertex_image?
[00:02:57.080 --> 00:02:59.360]   We can't see it in the file.
[00:02:59.360 --> 00:03:03.800]   It's in the file UnityCG.cginc.
[00:03:03.800 --> 00:03:05.720]   Why CG?
[00:03:05.720 --> 00:03:12.120]   Because the shader language used by earlier versions of Unity was CG, short for C for
[00:03:12.120 --> 00:03:13.840]   graphics.
[00:03:13.840 --> 00:03:18.960]   Earlier versions didn't use HLSL but the include files are still used.
[00:03:18.960 --> 00:03:22.960]   CG and HLSL are very similar.
[00:03:22.960 --> 00:03:27.920]   As well as converting the vertex from local space to clip space, a vertex shader will
[00:03:27.920 --> 00:03:36.440]   often pass other values such as colour, texture coordinates, UV and normals and other details.
[00:03:36.440 --> 00:03:44.680]   And standard Unity vertex shader vert_img passes these values in a V to F img struct.
[00:03:44.680 --> 00:03:50.360]   This struct is also defined in the include file UnityCG.cginc.
[00:03:50.360 --> 00:03:55.160]   Don't worry too much about the macros, the important thing is it passes the text_coord
[00:03:55.160 --> 00:03:58.920]   value as the struct property UV.
[00:03:58.920 --> 00:04:03.860]   All vertices will be processed before the fragment shader is called.
[00:04:03.860 --> 00:04:09.020]   A fragment shader's job is to return a colour value for each pixel.
[00:04:09.020 --> 00:04:16.440]   The magic of vertex fragment shaders is the values for the input are interpolated vertex
[00:04:16.440 --> 00:04:17.440]   values.
[00:04:17.440 --> 00:04:23.720]   So if we're in the middle of a triangle then the value for UV will be a blend of each vertex
[00:04:23.720 --> 00:04:25.660]   in the triangle.
[00:04:25.660 --> 00:04:28.800]   You might be wondering where the UV values come from.
[00:04:28.800 --> 00:04:34.920]   For a post-processing shader, the rendered source is supplied with the vertices automatically
[00:04:34.920 --> 00:04:42.720]   set so the bottom left will be correctly positioned on the screen and its UV value set to 0,0.
[00:04:42.720 --> 00:04:47.680]   The top right will have the UV set to 1,1 and the shader will set the pixels for two
[00:04:47.680 --> 00:04:53.260]   triangles with the vertices specified in a clockwise winding.
[00:04:53.260 --> 00:04:59.320]   If vertices are set anti-clockwise then the triangle's back-facing and by default the
[00:04:59.320 --> 00:05:01.900]   pixels would not be rendered.
[00:05:01.900 --> 00:05:04.000]   Let's just go over that again.
[00:05:04.000 --> 00:05:10.440]   The vertex function sets the clip position and sets up a struct, an interpolated form
[00:05:10.440 --> 00:05:13.440]   of which is passed to the fragment shader.
[00:05:13.440 --> 00:05:18.880]   Effectively all a fragment shader needs to do is return the colour for the pixel it's
[00:05:18.880 --> 00:05:23.900]   currently shading, that is a single pixel on the screen.
[00:05:23.900 --> 00:05:29.320]   The default graphics blip method uses a standard material to do the copying from the source
[00:05:29.320 --> 00:05:37.200]   to the destination but we can provide a material and specify a pass to use for the copying.
[00:05:37.200 --> 00:05:41.400]   Edit the blip method adding material 0.
[00:05:41.400 --> 00:05:46.760]   Now run the program and you won't see any change except the blip method is now using
[00:05:46.760 --> 00:05:51.840]   the shader attached to the material added as a property to this component.
[00:05:51.840 --> 00:05:59.020]   Just to prove this try multiplying the text2d line by float4 1001.
[00:05:59.020 --> 00:06:01.380]   Now the stars are all red.
[00:06:01.380 --> 00:06:04.720]   Don't forget to remove this after you've viewed the result.
[00:06:04.720 --> 00:06:13.060]   The function text2d takes two parameters, a sampler2d, a texture and a float2 value
[00:06:13.060 --> 00:06:19.140]   that defines which pixel to return from the texture, a uv value of 00 returns the bottom
[00:06:19.140 --> 00:06:27.800]   left pixel, 11 the top right and 0.5 0.5 the middle pixel, you get the idea.
[00:06:27.800 --> 00:06:31.800]   Using this pass we can copy the source to the destination.
[00:06:31.800 --> 00:06:36.240]   To complete this shader we're going to need some temporary textures to store intermediate
[00:06:36.240 --> 00:06:40.880]   stages of the rendering process, let's create them now.
[00:06:40.880 --> 00:06:49.640]   In the C# script add renderTexture brightnessText equal renderTexture getTemporary source.width
[00:06:49.640 --> 00:06:57.640]   divided by divide source.height divided by divide source.depth source.format renderTexture
[00:06:57.640 --> 00:07:04.880]   blurredText1 equals renderTexture getTemporary brightnessText descriptor.
[00:07:04.880 --> 00:07:12.680]   Then copy the blurredText1 line twice changing the texture name to blurredText2 compositeText.
[00:07:12.680 --> 00:07:19.040]   Because these are just temporary textures we'll need to delete them, so also add renderTexture
[00:07:19.040 --> 00:07:25.800]   releaseTemporary brightnessText and copy this three times replacing brightnessText with
[00:07:25.800 --> 00:07:34.320]   blurredText1, blurredText2, compositeText. And check it, whoops I missed the equals sign,
[00:07:34.320 --> 00:07:39.560]   that's better. Great we're ready to do the magic. Notice that all the temporary textures
[00:07:39.560 --> 00:07:46.200]   are smaller than the source. We divide width and height by the value divide. If divide
[00:07:46.200 --> 00:07:51.960]   is 2 then the width and height of the temporary textures are half the original source. You
[00:07:51.960 --> 00:07:57.160]   might be concerned that we're losing the resolution, but these temporary textures are composited
[00:07:57.160 --> 00:08:02.200]   with the source in a way that retains the quality of the original.
[00:08:02.200 --> 00:08:06.880]   The first stage is to create a version of the original that brightens the source. Pixels
[00:08:06.880 --> 00:08:12.840]   over a certain threshold are retained and enhanced using the intensity property. We
[00:08:12.840 --> 00:08:19.840]   pass these to the shader packed inside a single vector. Add material.setVector, brightnessSettingsID
[00:08:19.840 --> 00:08:31.280]   newVector3, thresholdIntensity, attenuation. Graphics.blit, source, brightnessText, material
[00:08:31.280 --> 00:08:38.840]   1. And change the blip pass zero line to use brightnessText. Now in the shader add another
[00:08:38.840 --> 00:08:45.920]   pass. It uses the standard vert-img vertex shader and a new fragment shader. Again we
[00:08:45.920 --> 00:08:51.600]   get the pixel colour using the text2d function, but this time we adjust the pixel colour by
[00:08:51.600 --> 00:08:58.280]   subtracting the value set for threshold, then using max to ensure that it is not less than
[00:08:58.280 --> 00:09:05.720]   zero. And we then multiply this new value by the value set as intensity. If we run the
[00:09:05.720 --> 00:09:12.920]   program now you get this brightness texture displayed. I promise, we're making progress.
[00:09:12.920 --> 00:09:20.920]   We've learnt a lot in this video. 1. A Unity shader uses shader lab syntax. 2. A Unity
[00:09:20.920 --> 00:09:29.320]   shader has properties and subshader sections. 3. A subshader contains one or more pass sections.
[00:09:29.320 --> 00:09:36.960]   4. A shader is split into a vertex shader and a fragment shader. 5. A vertex shader
[00:09:36.960 --> 00:09:45.240]   transforms a vertex position from local space to homogeneous clip space. 6. A fragment shader
[00:09:45.240 --> 00:09:52.440]   gets interpolated values depending on the pixel position within a triangle. 7. A fragment
[00:09:52.440 --> 00:09:58.320]   shader needs to return the colour value for the pixel it's rendering. 8. A fragment shader
[00:09:58.320 --> 00:10:04.880]   works on individual pixels. If you're new to vertex fragment shaders it's a lot to take
[00:10:04.880 --> 00:10:10.880]   in. Time for a short break, and in the next video we'll add more passes, merge them all
[00:10:10.880 --> 00:10:16.840]   together and create this effect. It'll be fun. Grab yourself a drink and I'll catch
[00:10:16.840 --> 00:10:17.640]   you in a moment.



# P18.-007-A-star-glow-effect-vertex

[00:00:00.000 --> 00:00:18.000]   A Star Glow Effect - Vertex Fragment Shaders Part 2
[00:00:18.000 --> 00:00:23.800]   So far creating this shader we've learnt about vertex fragment shaders and created a pass
[00:00:23.800 --> 00:00:29.640]   that creates the brightness texture, creating the basic source that we're going to manipulate
[00:00:29.640 --> 00:00:34.160]   to add the streaks to this output to create this effect.
[00:00:34.160 --> 00:00:39.920]   The next stage is to create streaks. This is a two stage process. We create a blurred
[00:00:39.920 --> 00:00:45.000]   version of the brightness texture with the blurring in a particular angle. Then we blur
[00:00:45.000 --> 00:00:51.440]   this image iteration count times. Let's start by creating the shader pass.
[00:00:51.440 --> 00:00:56.800]   This time we can't use the vert image function. We're going to create our own. So vertex is
[00:00:56.800 --> 00:01:03.560]   followed by vert. We need a couple of properties and a new struct, this time adding power and
[00:01:03.560 --> 00:01:11.040]   offset. Custom properties like these are given the semantics text_quad n, where n is a value
[00:01:11.040 --> 00:01:18.900]   greater than 0. Now the vertex function. This will return a V2F starglow struct. It receives
[00:01:18.900 --> 00:01:27.400]   an appdata_img parameter. Appdata_img is a struct defined in UnityCG.cginc. We must return
[00:01:27.400 --> 00:01:33.960]   a pos value, the sv position property. We simply take the local vertex position, pass
[00:01:33.960 --> 00:01:40.480]   to the function as the value v.vertex and use the method UnityObject to clip pos, again
[00:01:40.480 --> 00:01:48.680]   supplied in the include file. uv is just text_quad passed on. PowerText4 and raising it to the
[00:01:48.680 --> 00:01:56.360]   power iteration value -1. If iteration is 1 then power will be 4 raised to the power 0.
[00:01:56.360 --> 00:02:02.520]   Anything to the power 0 is 1. Iteration 2 power will equal 4. Iteration 3 power will
[00:02:02.520 --> 00:02:10.440]   equal 16. Offset takes the value mainTextTexelSize, which is 1 divided by pixelWidth for the x
[00:02:10.440 --> 00:02:17.080]   value and 1 divided by pixelHeight for the y value. So that's the vertex function. Now
[00:02:17.080 --> 00:02:23.960]   the fragment function. It receives a V2F starglow struct. We initialize a color value and a
[00:02:23.960 --> 00:02:29.800]   uv value, then repeat 4 times accumulating the color value by using the pixel value
[00:02:29.800 --> 00:02:35.920]   at uv multiplied by the attenuation value raised to the power input power times the
[00:02:35.920 --> 00:02:42.140]   loop variable j. The purpose of the pow function is to reduce the strength of the pixel color
[00:02:42.140 --> 00:02:48.780]   value we add to the target color. Suppose the target pixel is here. First we get the target
[00:02:48.780 --> 00:02:58.380]   pixel color. If attenuation equals 0.7 then power attenuation 0 equals 1. So we just multiply
[00:02:58.380 --> 00:03:06.040]   the target pixel by 1, setting color to the target pixel value. Then we move the uv value
[00:03:06.040 --> 00:03:14.280]   by adding offset. Now text2d sources a different pixel color. Because now j equals 1, the pow
[00:03:14.280 --> 00:03:23.920]   function is 0.7 to the power 1, or simply 0.7. Notice this is less than 1, because attenuation
[00:03:23.920 --> 00:03:31.200]   is restricted to the range 0 to 1. As the second parameter to the pow function increases,
[00:03:31.200 --> 00:03:38.380]   the return value decreases exponentially. We add this new slightly reduced level pixel
[00:03:38.380 --> 00:03:48.580]   to the color value. Then we move uv by offset again. This time we have pow 0.72 equals 0.49.
[00:03:48.580 --> 00:03:54.760]   When we add this new color, the strength is less again. Finally we move one more time
[00:03:54.760 --> 00:04:03.880]   and now pow equals 0.73 which equals 0.343. Reduced level again. And this is how we get
[00:04:03.880 --> 00:04:10.920]   the streaks. Now check the shader. Whoops, I missed the semicolon after the struct definition.
[00:04:10.920 --> 00:04:18.240]   And back in the C# script add float angle equals 360 divided by number of streaks. For
[00:04:18.240 --> 00:04:26.160]   int x equals 1, x is less than or equal to number of streaks. X plus plus. Vector2 offset
[00:04:26.160 --> 00:04:34.600]   equals quaternion angle axis. Angle times x plus angle of streak. Vector3 dot forward
[00:04:34.600 --> 00:04:42.840]   times vector2 dot down. Normalized. Material dot set vector. Offset id offset. Material
[00:04:42.840 --> 00:04:51.600]   dot set int. Iteration id 1. Graphics dot blit. Brightness text. Blurred text 1. Material
[00:04:51.600 --> 00:04:58.240]   2. Change the destination blit line to use blurred text 1. Now if you run the program
[00:04:58.240 --> 00:05:04.120]   you can see how the blur works. Remember it does this number of streaks times, changing
[00:05:04.120 --> 00:05:10.360]   the angle and so the offset value the shader uses each time it goes through the for loop.
[00:05:10.360 --> 00:05:17.280]   Here we only see the last output. Now add for int i equals 2, i is less than or equal
[00:05:17.280 --> 00:05:26.760]   to iteration i plus plus. Material dot set int. Iteration id i. Graphics dot blit. Blurred
[00:05:26.760 --> 00:05:34.560]   text 1. Blurred text 2. Material 2. Render texture temp equal blurred text 1. Blurred
[00:05:34.560 --> 00:05:40.560]   text 1 equals blurred text 2. Blurred text 2 equals temp. Each iteration through this
[00:05:40.560 --> 00:05:48.480]   for loop we use shader pass 2 to create blurred text 2 using blurred text 1 as the source.
[00:05:48.480 --> 00:05:53.980]   Having done this we swap the textures over, making the merged image blurred text 2 become
[00:05:53.980 --> 00:05:59.720]   the source image for the next loop. But at the moment we are only seeing one stage. The
[00:05:59.720 --> 00:06:06.440]   real magic happens by merging stages, but for that we need another shader pass. In the shader
[00:06:06.440 --> 00:06:14.740]   add another pass. The trick here is the blend mode. We use 1 minus disc colour 1, a soft
[00:06:14.740 --> 00:06:21.040]   additive blend. The trick here is the blend mode. When specifying a blend mode the first
[00:06:21.040 --> 00:06:26.980]   word gives the source factor and the second the destination factor. The source will be
[00:06:26.980 --> 00:06:32.920]   multiplied by the source factor and added to the destination multiplied by the destination
[00:06:32.920 --> 00:06:38.600]   factor, like this. Understanding blend modes is easiest if you think about the numbers
[00:06:38.600 --> 00:06:44.980]   each channel will have. A single channel is clamped between 0 and 1. How much colour can
[00:06:44.980 --> 00:06:51.520]   you add to a colour RGB in the frame buffer before you get this clamp? Pause and think
[00:06:51.520 --> 00:07:02.680]   about it. The answer is 1 minus R, 1 minus G, 1 minus B, because 1 minus R, 1 minus G,
[00:07:02.680 --> 00:07:12.720]   1 minus B plus RGB equals 111, or white. Thus 1 minus R, 1 minus G, 1 minus B, i.e. 1 minus
[00:07:12.720 --> 00:07:18.360]   disc colour, is the maximum amount of colour that you can add without colour clamping after
[00:07:18.360 --> 00:07:24.640]   blending. The vertex function is simply vert image and all we need to do for the frag function
[00:07:24.640 --> 00:07:30.560]   is return the text 2D output. Because of the blend mode we get a soft additive of main
[00:07:30.560 --> 00:07:36.240]   text to the existing source. Now we have this third pass, we can use it to merge our blur
[00:07:36.240 --> 00:07:46.240]   passes. Back in the C# script add graphics.blit, blurred text 1, composite text, material 3,
[00:07:46.240 --> 00:07:51.760]   and change the destination blit to display the composite text. Now if we run the program
[00:07:51.760 --> 00:07:57.580]   we get the blurred streaks. We're closing in on the final output. Back in the shader
[00:07:57.580 --> 00:08:03.680]   we have one more pass to add that will merge the composite texture and the source. Again
[00:08:03.680 --> 00:08:10.440]   we use the include version of the vertex shader vert image. In this pass we get a second texture,
[00:08:10.440 --> 00:08:16.960]   composite texture, and a colour value, composite colour. We use the input.uv value to get a
[00:08:16.960 --> 00:08:22.320]   pixel colour value from the main text, which for this last pass is going to be the rendered
[00:08:22.320 --> 00:08:27.700]   source. And we get a colour value from the composite texture we've created over the last
[00:08:27.700 --> 00:08:33.680]   passes. We can optionally take a greyscale version of the pixel colour and multiply this
[00:08:33.680 --> 00:08:38.680]   by the composite colour. Comment this out to just take the composite colour. Then we add
[00:08:38.680 --> 00:08:43.920]   this to the source colour pixel using saturates to clamp each component of the float 4 to
[00:08:43.920 --> 00:08:50.040]   a value between 0 and 1. All we need to do now is use this pass to merge the composite
[00:08:50.040 --> 00:08:58.040]   texture with the source texture. Back in the C# script add material.setColour, compositeColourID,
[00:08:58.040 --> 00:09:06.520]   colour, material.setTexture, compositeTextID, compositeText, and change the destination
[00:09:06.520 --> 00:09:13.720]   blit to use source and pass for. And there you have a nice star glow effect. The same
[00:09:13.720 --> 00:09:18.680]   effect could be achieved using compute shaders, but it's important for later examples that
[00:09:18.680 --> 00:09:23.920]   you have an understanding of using vertex fragment shaders. And that completes the post
[00:09:23.920 --> 00:09:30.120]   processing section. Just a simple challenge to complete, and then a quick quiz before
[00:09:30.120 --> 00:09:35.040]   we look at particle effects and flocking. In the next section, keep watching!
[00:09:36.520 --> 00:09:38.580]   you



# P19.-008-Challenge-Create-a-sepia-

[00:00:00.000 --> 00:00:13.000]   [Music]
[00:00:13.000 --> 00:00:14.000]   Challenge
[00:00:14.000 --> 00:00:18.000]   Add a shaded tint effect to the bottom of the screen
[00:00:18.000 --> 00:00:22.000]   Open the scene "Challenge 3" from the start project
[00:00:22.000 --> 00:00:26.000]   and in Visual Studio open "challenge3.compute"
[00:00:26.000 --> 00:00:28.000]   Can you edit the code in the shader
[00:00:28.000 --> 00:00:32.000]   So you can, one, add a darkened band at the base of the screen
[00:00:32.000 --> 00:00:35.000]   Possibly to be a background for a lettering overlay
[00:00:35.000 --> 00:00:39.000]   Two, the height of the area should be adjustable
[00:00:39.000 --> 00:00:43.000]   Three, the softness of the edge of this area should be adjustable
[00:00:43.000 --> 00:00:49.000]   And four, make this area tintable with an adjustable tint strength
[00:00:49.000 --> 00:00:53.000]   The template already passes the necessary properties to the shader
[00:00:53.000 --> 00:00:56.000]   All your code should just be in the compute shader
[00:00:56.000 --> 00:00:59.000]   I'd spend no more than 20 minutes on this challenge
[00:00:59.000 --> 00:01:01.000]   Pause the video now
[00:01:01.000 --> 00:01:08.000]   How did that go?
[00:01:08.000 --> 00:01:11.000]   My solution is first remove the assignment from colour
[00:01:11.000 --> 00:01:12.000]   Then add
[00:01:12.000 --> 00:01:28.000]   If "id.y" is less than "uint" tint height, float3grayscale = sourceColor.r + sourceColor.g + sourceColor.b * 0.33 * tintColor.rgb
[00:01:28.000 --> 00:01:37.000]   float3shaded = lerp, sourceColor.rgb, grayscale, tintStrength * shade
[00:01:37.000 --> 00:01:45.000]   floatSourceAmount = smoothstep, tintHeight - edgeWidth, tintHeight, floatid.y
[00:01:45.000 --> 00:01:54.000]   colour = lerp, float4shaded1, sourceColor, sourceAmount, elseColor = sourceColor
[00:01:54.000 --> 00:02:01.000]   Here, if our current y value is less than the property tintHeight, we create a grayscale image
[00:02:01.000 --> 00:02:09.000]   by summing the channels and dividing by 3. Here we multiply by 0.33, which is the same thing
[00:02:09.000 --> 00:02:12.000]   Then we multiply this by the tintColor
[00:02:12.000 --> 00:02:17.000]   We create the tint of the source and the grayscale using the tintStrength property
[00:02:17.000 --> 00:02:20.000]   and then darken it using the shade property
[00:02:20.000 --> 00:02:28.000]   To allow for the softened edge, we use smoothstep subtracting the edgeWidth value from the lower limit parameter 1
[00:02:28.000 --> 00:02:36.000]   To create the final colour, we merge the shaded value with the source value using the proportional value we got from smoothstep
[00:02:36.000 --> 00:02:43.000]   Of course, if the current pixel y value is greater or equal to tintHeight, then we just set it as the sourceColor
[00:02:43.000 --> 00:02:51.000]   Now you can adjust the height, the softness, the tintColor, its strength and its shade. Nice work!
[00:02:51.000 --> 00:02:56.000]   Just a quick quiz then onto particles and flocking. See you in a minute!
[00:02:58.000 --> 00:03:08.000]   [BLANK_AUDIO]

