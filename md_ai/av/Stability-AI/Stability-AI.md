# 0.github urls

https://github.com/Stability-AI/stablediffusion

https://github.com/Stability-AI/StableCascade


SwarmUI v0.9.6 Beta:  https://github.com/mcmonkeyprojects/SwarmUI.git

# 1.Stable Cascade

Stable Cascade是由Stability AI推出的新一代文本生成图像模型。以下是关于它的详细介绍：

### 特点
- **高质量图像生成**：能生成高质量图像，在生成清晰文本方面表现出色，官方用户研究显示其生成的图像质量优于SDXL，在遵循提示词方面也略胜一筹。
- **基于Würstchen架构**：采用独特的三阶段架构，包括阶段A、B和C。阶段C是采样过程，设置图像的全局构图；阶段B负责在潜在空间中填充细节；阶段A应用VAE解码器将潜在图像转换为像素图像。
- **高效训练和微调**：基于其模型设计，只需微调阶段C模型就能实现自定义风格或控制网络，相比SDXL，更易于训练和添加控制网络。并且在消费级硬件上训练和微调也异常容易，降低了对硬件的要求，官方称即便仅配备20GB显存，模型也能流畅运行。
- **潜在空间小**：与传统的文本到图像生成模型相比，Stable Cascade使用更小的潜在空间进行训练和推理，因此在训练和推理速度上都有显著提升。

### 应用场景
- **内容创作**：为艺术家、设计师等提供灵感和创作素材，帮助快速生成各种风格的插画、绘画作品以及设计概念图等。
- **设计领域**：可用于广告设计、产品包装设计、室内设计等，快速生成设计初稿或参考图像，提高设计效率。
- **教育领域**：辅助教学，例如生成历史场景、科学实验场景等图像，帮助学生更好地理解知识；也可用于艺术教育，培养学生的创造力和审美能力。
- **娱乐产业**：用于游戏开发中的角色设计、场景设计，以及电影、动画制作中的概念设计、分镜头脚本绘制等。

需要注意的是，该模型发布在仅允许非商业使用的非商业许可下。

======================================================================
# 2.Generative Models by Stability AI
Stability AI的生成模型（Generative Models by Stability AI）是一系列开源模型，基于Stable Diffusion框架，可生成图像、音频、视频和文本等多种媒体内容。相关介绍如下：
- **模型类型**
    - **Stable Diffusion XL（SDXL）**：文本到图像模型，能根据自然语言提示生成高分辨率、细节丰富且构图复杂的图像。
    - **Stable Diffusion Audio（SDA）**：文本到音频模型，可从自然语言提示中生成逼真且富有表现力的语音、音乐和音效。
    - **Stable Diffusion Video（SDV）**：文本到视频模型，能够生成具有动态、光照和场景变化的逼真视频。
    - **Stable Diffusion Language（SDL）**：文本到文本模型，可以生成具有各种风格、语气和格式的自然且连贯的文本。
- **新发布模型**
    - **Stable Video 4D（SV4D）**：视频到4D扩散模型，用于新颖视角的视频合成。可生成40帧（5个视频帧x8个相机视角），分辨率为576x576的视频。
    - **SV3D**：图像到视频模型，用于新颖的多视角合成。给定1个上下文帧，可生成21帧，分辨率为576x576的视频。
    - **SDXL - Turbo**：快速的文本到图像模型，能快速生成高质量图像。
- **模型特点**
    - **开放免费**：部分模型如Stable Diffusion 3.5系列在特定许可下，商业和非商业使用均免费，降低了使用门槛。
    - **可定制性强**：一些模型高度可定制，能满足不同用户在不同场景下的需求，且适合在消费级硬件上运行。
- **应用场景**
    - **视频制作**：视频创作者使用Stable Video Diffusion模型，能轻松生成视频片段，丰富视频内容。
    - **音频创作**：音乐创作者借助Stable Audio 2.0生成独特的音乐和音效，为音乐作品增添新的元素。
- **使用途径**
    - **API**：通过Stability AI API，开发者可将模型功能集成到应用程序中。
    - **Stable Assistant**：可通过Stable Assistant，即Stability AI的基于网页的创意平台，访问所有模型和编辑工具。

======================================================================
# 3.StableSwarmUI
StableSwarmUI 是一个基于 Web 的开源界面，专为 Stable Diffusion 设计，提供直观、功能丰富的图像生成和编辑体验。以下是其核心特点和使用指南：


### **主要功能**
1. **多模型支持**  
   - 兼容 SDXL、Stable Cascade、Kandinsky 等主流文本到图像模型。
   - 支持同时加载多个模型，一键切换。

2. **直观的界面**  
   - 拖放式工作流，适合初学者和专业人士。
   - 实时预览生成过程，支持图像缩放和细节检查。

3. **高级控制工具**  
   - **提示词工程**：支持复杂提示词结构（如权重、否定提示）。
   - **图像控制**：内置 ControlNet、IP - Adapter 等，支持姿势控制、线条引导等。
   - **批量生成**：支持参数网格搜索，快速测试不同组合。

4. **社区与协作**  
   - 内置画廊功能，方便保存和分享作品。
   - 支持插件扩展，可自定义功能。


### **安装与使用**
1. **本地部署**  
   ```bash
   # 克隆仓库
   git clone https://github.com/Stability-AI/StableSwarmUI.git
   cd StableSwarmUI

   # 安装依赖（需要Python和Node.js）
   pip install -r requirements.txt
   npm install

   # 启动应用
   python server.py
   ```
   访问 `http://localhost:7860` 即可使用。

2. **在线版本**  
   可通过 Stability AI 的官方平台直接访问，无需本地安装。


### **核心优势**
- **性能优化**：针对消费级硬件优化，支持低显存设备。
- **多模态支持**：未来将集成文本、音频、视频生成功能。
- **开源自由**：基于 AGPL - 3.0 许可，可自由修改和分发。


### **应用场景**
- **艺术创作**：生成概念艺术、插画、漫画等。
- **设计工作**：快速生成UI/UX原型、产品渲染图。
- **内容生产**：为社交媒体、广告生成视觉素材。


### **与其他工具对比**
| 特性                | StableSwarmUI       | Automatic1111       | DreamStudio         |
|---------------------|---------------------|---------------------|---------------------|
| 开源免费            | ✅                  | ✅                  | ❌（需付费订阅）    |
| 多模型支持          | ✅                  | ✅                  | ❌（仅官方模型）    |
| 高级控制网络        | ✅                  | ✅                  | ❌                  |
| 云端部署            | ❌（本地优先）      | ❌（本地优先）      | ✅                  |
| 学习曲线            | 中等                | 较高                | 低                  |


### **资源链接**
- **GitHub 仓库**：[Stability-AI/StableSwarmUI](https://github.com/Stability-AI/StableSwarmUI)
- **文档**：[官方Wiki](https://github.com/Stability-AI/StableSwarmUI/wiki)
- **社区**：[Discord](https://discord.gg/stabilityai)


如果需要特定功能的详细教程（如 ControlNet 使用、多模型配置），可以告诉我！     

======================================================================
# 4.comfyui

ComfyUI是一个基于节点流程的Stable Diffusion操作界面。它将图像生成流程拆分为各个节点，用户可通过自定义节点、拖拽连线来定制工作流，实现更复杂、自由度更高的图像生成任务。以下是具体介绍：
- **特点**
    - **轻量级且快速**：资源占用较低，能在较低配置设备上流畅运行，图像生成速度较快，可提高创作效率。
    - **高度灵活可配置**：用户可将代表特定功能（如加载模型、输入提示等）的节点自由链接，构建各种复杂工作流程，实现个性化图像生成效果。
    - **工作流透明直观**：以可视化的节点和连线呈现图像生成流程，用户能清晰看到数据流向和节点处理结果，便于理解原理、调试和优化工作流程。
    - **易于共享传播**：工作流可保存为文件，用户可方便地分享自己的工作流，也可下载使用他人分享的，促进知识和经验交流。
- **支持模型**：支持多种文本到图像模型，如SD 1.x、SD 2.x、SDXL、SDXL Turbo、Stable Cascade、SD3、SD 3.5等，还支持Stable Video Diffusion等视频模型以及Stable Audio等音频模型。
- **安装方式**：可通过下载Windows便携包，解压后直接运行。也可使用comfy-cli安装，命令为“pip install comfy-cli”  “comfy install”。还可手动安装，需克隆仓库，将模型文件放入指定目录，不同类型GPU还需安装相应的依赖。
- **应用场景**：适用于数字艺术家、AI研究人员、内容创作者等用户群体，可用于文本到图像、图像到图像、老照片修复等多种场景，也适合进行图像生成的原型设计。
- **与其他工具对比**：与Automatic1111相比，ComfyUI更灵活、透明，且运行速度快，但界面可能因不同工作流而布局不同，对于普通用户来说，学习成本相对较高，存在一定上手难度。

======================================================================
 